# osu!风格谱面生成器 - 模型训练实现计划

## 概述

本文档详细描述了osu!风格谱面生成器中深度学习模型的训练实现计划，包括数据加载器、训练循环、损失函数和评估指标的设计与实现。该计划旨在基于已实现的Transformer模型架构和数据处理功能，完成模型训练和评估的全部流程。

项目当前状态：
1. 模型架构（Transformer编码器-解码器）已经实现
2. 数据处理模块已完全实现，包括数据集扫描、处理、分割和导出功能
3. GUI界面中的训练界面框架已构建完成
4. 训练线程基础框架已实现

本计划将重点关注如何使用已处理好的数据集来训练模型，并实现完整的评估和生成流程。

## 实现计划

### 1. 数据加载器实现 (待实现)

以下是数据加载器的设计和实现计划，需要基于已处理好的数据集文件（JSON格式）开发专用的数据集类和加载器：

#### 1.1 数据集类设计

```python
class BeatmapDataset(torch.utils.data.Dataset):
    """
    谱面数据集类 - 用于加载音频特征和谱面标签
    """
    def __init__(self, 
                 dataset_path: str,
                 split: str = "train",
                 max_sequence_length: int = 1024,
                 feature_transform = None,
                 target_transform = None):
        """
        初始化数据集
        
        参数:
            dataset_path: 数据集根目录，包含train/val/test子目录
            split: 数据集分割，可选"train"、"val"或"test"
            max_sequence_length: 最大序列长度
            feature_transform: 特征变换函数
            target_transform: 目标变换函数
        """
        self.dataset_path = dataset_path
        self.split = split
        self.max_sequence_length = max_sequence_length
        self.feature_transform = feature_transform
        self.target_transform = target_transform
        self.samples = []
        
        # 加载数据集文件
        dataset_file = os.path.join(dataset_path, split, "dataset.json")
        if os.path.exists(dataset_file):
            with open(dataset_file, 'r', encoding='utf-8') as f:
                self.dataset = json.load(f)
                self.samples = self.dataset.get('samples', [])
        
    def __len__(self):
        return len(self.samples)
        
    def __getitem__(self, idx):
        # 从samples中获取对应的特征和谱面数据
        sample = self.samples[idx]
        
        # 提取特征和标签
        audio_features = np.array(sample['audio_features'])
        beatmap_data = np.array(sample['beatmap_data'])
        
        # 应用变换
        if self.feature_transform:
            audio_features = self.feature_transform(audio_features)
        
        if self.target_transform:
            beatmap_data = self.target_transform(beatmap_data)
            
        # 转换为张量
        audio_features = torch.tensor(audio_features, dtype=torch.float32)
        beatmap_data = torch.tensor(beatmap_data, dtype=torch.float32)
        
        return {'audio_features': audio_features, 'beatmap_data': beatmap_data}
```

#### 1.2 数据加载器实现

```python
def create_dataloaders(
    dataset_path: str,
    batch_size: int = 8,
    shuffle: bool = True,
    num_workers: int = 4
):
    """
    创建训练和验证数据加载器
    
    参数:
        dataset_path: 数据集根目录
        batch_size: 批次大小
        shuffle: 是否打乱数据
        num_workers: 加载线程数量
        
    返回:
        训练数据加载器、验证数据加载器和测试数据加载器
    """
    # 创建数据集
    train_dataset = BeatmapDataset(
        dataset_path=dataset_path,
        split="train"
    )
    
    val_dataset = BeatmapDataset(
        dataset_path=dataset_path,
        split="val"
    )
    
    test_dataset = BeatmapDataset(
        dataset_path=dataset_path,
        split="test"
    )
    
    # 创建数据加载器
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, val_loader, test_loader
```

### 2. 损失函数设计与实现

#### 2.1 组合损失函数

```python
class BeatmapLoss(nn.Module):
    """
    谱面生成损失函数 - 组合多种损失
    """
    def __init__(self, 
                 object_type_weight: float = 1.0, 
                 position_weight: float = 1.0,
                 timing_weight: float = 1.5):
        """
        初始化损失函数
        
        参数:
            object_type_weight: 物件类型损失权重
            position_weight: 位置损失权重
            timing_weight: 时间损失权重
        """
        super().__init__()
        self.object_type_weight = object_type_weight
        self.position_weight = position_weight
        self.timing_weight = timing_weight
        
    def forward(self, predictions, targets, mask=None):
        """
        计算损失
        
        参数:
            predictions: 模型预测，包含物件类型、位置和时间
            targets: 目标标签，包含物件类型、位置和时间
            mask: 有效位置掩码
            
        返回:
            总损失值和各部分损失
        """
        # 计算物件类型损失（交叉熵）
        # 计算位置损失（均方误差或平滑L1损失）
        # 计算时间损失（均方误差或平滑L1损失）
        # 应用节奏一致性约束
        # 计算加权总损失
```

#### 2.2 节奏一致性损失

```python
def rhythm_consistency_loss(timing_predictions, timing_targets, beat_intervals, mask=None):
    """
    节奏一致性损失 - 惩罚与节拍不一致的物件放置
    
    参数:
        timing_predictions: 预测的物件时间
        timing_targets: 目标物件时间
        beat_intervals: 节拍间隔信息
        mask: 有效位置掩码
        
    返回:
        节奏一致性损失值
    """
    # 计算预测时间与最近节拍的距离
    # 与目标时间到最近节拍距离的差异
    # 返回损失值
```

### 3. 训练循环实现

#### 3.1 训练函数

```python
def train_epoch(
    model: nn.Module,
    dataloader: DataLoader,
    criterion: nn.Module,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    epoch: int,
    scheduler = None,
    clip_grad_norm: float = 1.0
) -> Dict[str, float]:
    """
    单轮训练
    
    参数:
        model: 模型
        dataloader: 数据加载器
        criterion: 损失函数
        optimizer: 优化器
        device: 设备（CPU/GPU）
        epoch: 当前轮次
        scheduler: 学习率调度器
        clip_grad_norm: 梯度裁剪范数
        
    返回:
        训练指标字典
    """
    # 初始化指标
    # 遍历数据批次
    # 计算损失
    # 反向传播
    # 梯度裁剪
    # 参数更新
    # 更新指标
    # 返回训练指标
```

#### 3.2 验证函数

```python
def validate(
    model: nn.Module,
    dataloader: DataLoader,
    criterion: nn.Module,
    device: torch.device
) -> Dict[str, float]:
    """
    验证函数
    
    参数:
        model: 模型
        dataloader: 数据加载器
        criterion: 损失函数
        device: 设备（CPU/GPU）
        
    返回:
        验证指标字典
    """
    # 初始化指标
    # 禁用梯度计算
    # 遍历数据批次
    # 计算损失
    # 更新指标
    # 返回验证指标
```

#### 3.3 完整训练流程

```python
def train_model(
    model: nn.Module,
    train_dataloader: DataLoader,
    val_dataloader: DataLoader,
    criterion: nn.Module,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    num_epochs: int = 50,
    patience: int = 5,
    checkpoint_dir: str = "./checkpoints",
    scheduler = None
) -> Dict[str, List]:
    """
    完整训练流程
    
    参数:
        model: 模型
        train_dataloader: 训练数据加载器
        val_dataloader: 验证数据加载器
        criterion: 损失函数
        optimizer: 优化器
        device: 设备（CPU/GPU）
        num_epochs: 训练轮次
        patience: 早停耐心值
        checkpoint_dir: 检查点保存目录
        scheduler: 学习率调度器
        
    返回:
        训练历史记录
    """
    # 初始化历史记录和早停计数器
    # 遍历训练轮次
    # 训练一个轮次
    # 验证模型
    # 保存检查点
    # 判断是否早停
    # 保存最终模型
    # 返回训练历史记录
```

### 4. 模型评估指标设计

#### 4.1 谱面质量评估

```python
def evaluate_beatmap_quality(
    model: nn.Module,
    test_dataloader: DataLoader,
    device: torch.device
) -> Dict[str, float]:
    """
    评估谱面质量
    
    参数:
        model: 模型
        test_dataloader: 测试数据加载器
        device: 设备（CPU/GPU）
        
    返回:
        评估指标字典
    """
    # 初始化指标
    # 生成谱面
    # 计算物件分布指标
    # 计算节奏一致性指标
    # 计算难度准确性指标
    # 返回评估指标
```

#### 4.2 自定义评估指标

```python
def rhythm_consistency_score(predictions, beat_times):
    """
    节奏一致性评分 - 衡量物件放置与节拍的一致性
    """
    # 计算物件放置与最近节拍的距离
    # 返回一致性得分

def difficulty_accuracy_score(predictions, target_difficulty):
    """
    难度准确性评分 - 衡量生成谱面与目标难度的匹配程度
    """
    # 计算物件密度
    # 计算物件复杂度
    # 计算与目标难度的匹配度
    # 返回准确性得分
```

## 实施时间线

1. **数据加载器实现**：2天
2. **损失函数设计与实现**：2天
3. **训练循环实现**：2天
4. **评估指标设计**：1天
5. **集成与测试**：3天

总计预计时间：10天（2周工作日）

## 注意事项

1. 实现中需要保持与现有模型架构的兼容性
2. 损失函数设计需考虑谱面生成的特殊性，尤其是节奏一致性
3. 训练过程中需加入适当的正则化以防止过拟合
4. 评估指标应当尽可能量化谱面的质量和可玩性
5. 模型检查点保存应包含足够信息以便后续加载和生成 